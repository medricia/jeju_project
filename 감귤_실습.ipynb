{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 하이퍼 파라미터 설정"
      ],
      "metadata": {
        "id": "NcNc4fbfkGXX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qi7OiE52g228"
      },
      "outputs": [],
      "source": [
        "# train, validation 비율\n",
        "test_size = 0.2\n",
        "\n",
        "# 하이퍼파라미터\n",
        "batch_size = 32\n",
        "learning_rate = 0.001\n",
        "num_epochs = 10\n",
        "\n",
        "# 모델 인스턴스\n",
        "input_size_x = 224\n",
        "input_size_y = 224\n",
        "input_size = input_size_x * input_size_y * 3\n",
        "hidden_size = 128\n",
        "num_classes = 2 # 한라봉, 감귤\n",
        "\n",
        "# 데이터셋 경로\n",
        "data_dir      = '/content/drive/MyDrive/jeju_data/Training/원천데이터'\n",
        "test_data_dir = '/content/drive/MyDrive/jeju_data/Test/원천데이터'\n",
        "model_save_path = '/content/drive/MyDrive/jeju_data/model.pth'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 필요한 도구 불러오기"
      ],
      "metadata": {
        "id": "zHtlEEs6kK42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "-zCSe4Y5kPih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU가 있는 경우\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UR4jYP8JIsM0",
        "outputId": "611dbca8-9f77-480d-cc6d-b730fb9b4eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_remove_element(ls, value):\n",
        "    try:\n",
        "        ls.remove(value)\n",
        "    except ValueError:\n",
        "        pass\n",
        "    return ls\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = data_dir\n",
        "        self.transform = transform\n",
        "        self.classes = safe_remove_element(os.listdir(data_dir), '.ipynb_checkpoints')\n",
        "        self.class_to_dix = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
        "        self.images = self._load_images()\n",
        "\n",
        "    def _load_images(self):\n",
        "        images = []\n",
        "        for cls_name in self.classes:\n",
        "            class_dir = os.path.join(self.data_dir, cls_name)\n",
        "            for img_name in os.listdir(class_dir):\n",
        "                img_path = os.path.join(class_dir, img_name)\n",
        "                images.append((img_path, cls_name))\n",
        "        return images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, cls_name = self.images[idx]\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        label = self.class_to_dix[cls_name] # 클래스 이름을 인덱스로 변환\n",
        "        return image, label\n",
        "\n",
        "\n",
        "class SimpleModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(SimpleModel, self).__init__()\n",
        "        self.flatten = nn.Flatten() # nn.view(-1, ~~~)\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def train_epoch(model, data_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in tqdm(data_loader):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(images.to(device))\n",
        "        loss = criterion(output, labels.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * images.size(0)\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader.dataset)\n",
        "    return epoch_loss\n",
        "\n",
        "\n",
        "def evaluate_model(model, data_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in data_loader:\n",
        "            labels = labels.to(device)\n",
        "            output = model(images.to(device))\n",
        "            loss = criterion(output, labels)\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "            _, predicted = torch.max(output, dim=1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted.to(device) == labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(data_loader.dataset)\n",
        "    accuarcy = correct/total\n",
        "    return epoch_loss, accuarcy\n",
        "\n",
        "\n",
        "def train_run(model, num_epochs, train_loader, eval_loader, optimizer, criterion):\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
        "        val_loss, accuarcy = evaluate_model(model, eval_loader, criterion)\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}] :',\n",
        "              f'Train Loss: {train_loss},',\n",
        "              f'Validation Loss: {val_loss},',\n",
        "              f'accuarcy: {accuarcy}'\n",
        "        )\n",
        "\n",
        "transfrom = transforms.Compose([\n",
        "    transforms.Resize((input_size_x, input_size_y)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "S40xvC2bk4jk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 불러오기"
      ],
      "metadata": {
        "id": "YU6ddJMyDII9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_dataset = CustomDataset(data_dir, transform=transfrom)\n",
        "\n",
        "train_indces, eval_indices = train_test_split(list(range(len(custom_dataset))), test_size=test_size, random_state=0)\n",
        "\n",
        "train_dataset = torch.utils.data.Subset(custom_dataset, train_indces)\n",
        "eval_dataset = torch.utils.data.Subset(custom_dataset, eval_indices)\n",
        "test_dataset = CustomDataset(test_data_dir, transform=transfrom)\n",
        "\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
        "eval_data_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "RS7tEn7C-UNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 생성"
      ],
      "metadata": {
        "id": "ltRJj8DqFKYg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "simple_model = SimpleModel(input_size, hidden_size, num_classes)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(simple_model.parameters(), lr=learning_rate)\n",
        "\n",
        "train_run(simple_model, num_epochs, train_data_loader, eval_data_loader, optimizer, criterion)\n",
        "epoch_loss, accuarcy = evaluate_model(simple_model, test_data_loader, criterion)\n",
        "print(f'Test Loss: {epoch_loss:.4f}, Test Accuarcy: {accuarcy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_ZZsxkJFIo-",
        "outputId": "e7e22830-b7ca-4bfb-c2f0-ac8cd8476e7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51/51 [01:01<00:00,  1.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10] : Train Loss: 6.1031109680520785, Validation Loss: 0.33397185550468445, accuarcy: 0.9276807980049875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51/51 [01:01<00:00,  1.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [2/10] : Train Loss: 0.1566804214306513, Validation Loss: 0.3870053716431235, accuarcy: 0.8902743142144638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51/51 [01:01<00:00,  1.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [3/10] : Train Loss: 0.07641817151369441, Validation Loss: 0.03502377862189989, accuarcy: 0.9925187032418953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51/51 [00:59<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [4/10] : Train Loss: 0.02667058571461293, Validation Loss: 0.038442157013285176, accuarcy: 0.9925187032418953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51/51 [00:58<00:00,  1.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [5/10] : Train Loss: 0.04496845954903764, Validation Loss: 0.05847078504782695, accuarcy: 0.9825436408977556\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51/51 [00:59<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [6/10] : Train Loss: 0.018763095622115266, Validation Loss: 0.05400485193628749, accuarcy: 0.9875311720698254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51/51 [00:57<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [7/10] : Train Loss: 0.015045342595781117, Validation Loss: 0.051908056299896574, accuarcy: 0.9900249376558603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51/51 [00:59<00:00,  1.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [8/10] : Train Loss: 0.01570349238954833, Validation Loss: 0.030882967714718317, accuarcy: 0.9925187032418953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51/51 [00:58<00:00,  1.15s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [9/10] : Train Loss: 0.011721620592055632, Validation Loss: 0.02763200595775441, accuarcy: 0.9925187032418953\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 51/51 [00:57<00:00,  1.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/10] : Train Loss: 0.01605386589601186, Validation Loss: 0.022285179110206756, accuarcy: 0.9950124688279302\n",
            "Test Loss: 0.0212, Test Accuarcy: 0.9921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장\n",
        "torch.save(simple_model.state_dict(), model_save_path)"
      ],
      "metadata": {
        "id": "3YetAjhDHkJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 불러오기\n",
        "simple_model = SimpleModel(input_size, hidden_size, num_classes)\n",
        "simple_model.load_state_dict(torch.load(model_save_path))\n",
        "simple_model.eval()"
      ],
      "metadata": {
        "id": "hpReWtR-Gmvh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}